{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2086dfd4-9e2a-4a83-bd51-89f6fbd3d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from models import *\n",
    "import torch\n",
    "import pytorchvideo\n",
    "from pytorchvideo.data import labeled_video_dataset\n",
    "from pytorchvideo.data.clip_sampling import make_clip_sampler\n",
    "from pytorchvideo.transforms import ApplyTransformToKey, RandomResizedCrop, Normalize, RandomShortSideScale, RemoveKey, ShortSideScale, UniformTemporalSubsample\n",
    "import torchvision.transforms as transforms \n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import pytorchvideo.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.models.video as v_model\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "leg = 'R'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff9c07ff-1722-40fe-b50f-a2a15154f8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded!\n"
     ]
    }
   ],
   "source": [
    "model = v_model.r3d_18()\n",
    "model = model.to(device)\n",
    "\n",
    "checkpoint = torch.load(f'./hint_model_{leg}/right_model_6.pt' if leg == 'R' else f'./hint_model_{leg}/left_model_49.pt') \n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "model.eval()\n",
    "print(\"model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9881ebe5-cc27-42ad-8a8d-f262e214470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "            [\n",
    "            ApplyTransformToKey(\n",
    "              key=\"video\",\n",
    "              transform = transforms.Compose(\n",
    "                  [\n",
    "                    #UniformTemporalSubsample(8),\n",
    "                    #Lambda(lambda x: x / 255.0),\n",
    "                    Normalize((0.45, 0.45, 0.45), (0.225, 0.225, 0.225)),\n",
    "                    #RandomShortSideScale(min_size=256, max_size=320),\n",
    "                    #RandomCrop(244),\n",
    "                    transforms.Resize((192,108)),\n",
    "                    #transforms.RandomHorizontalFlip(p=0.5),\n",
    "                  ]\n",
    "                ),\n",
    "              ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "batch_size = 3\n",
    "num_sec = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d79196a4-2b51-42da-935c-4c8a068e69b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clip_sampler = make_clip_sampler('random', num_sec)\n",
    "dataset = labeled_video_dataset(f'valid_set_{leg}', clip_sampler, transform=train_transform)\n",
    "#train_set, valid_set = random_split(dataset, [int(len(dataset) * 0.8), len(dataset) - int(len(dataset) * 0.8)])\n",
    "test_loader = DataLoader(dataset, batch_size = 3)\n",
    "#valid_loader = DataLoader(valid_set, batch_size = 3, shuffle = False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bbd2b6b-82dc-4dd4-b74c-f13ed709fbaa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:11,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc = 0.4166666865348816, loss = 0.3619750291109085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "valid_loss = 0\n",
    "total = 0\n",
    "accuracy = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "            imgs, labels = batch['video'], batch['label']\n",
    "            #print(batch['video_name'])\n",
    "            #print(batch['clip_start'])\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            #print(preds, labels)\n",
    "\n",
    "            # calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # add loss\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            # add accuracy\n",
    "            total += imgs.shape[0]\n",
    "            accuracy += torch.sum(preds == labels.data)\n",
    "print(f\"test acc = {accuracy / total}, loss = {valid_loss / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa89c810-9347-463b-a782-4255f953967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "HAO SE O"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
